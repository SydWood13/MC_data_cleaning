{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74a98d19-9888-4fda-92b6-18be422079b2",
   "metadata": {},
   "source": [
    "# Scraping Gradescope\n",
    "\n",
    "Why is this necessary? Because Gradescope doesn't provide any way to export a complete list of all rubric items with each student's applied items, just aggregated scores on a per-problem or per-assignment basis.\n",
    "\n",
    "We need everything. All of it.\n",
    "\n",
    "So this is a notebook to automate some of the scraping.\n",
    "\n",
    "I really want to control an existing chrome profile, but sadly this seems annoyingly difficult to figure out for selenium 4, so we'll have to settle for manual login..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fde412e-d948-4ddb-ab82-141cd01a73cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\woods\\.wdm\\drivers\\chromedriver\\win64\\125.0.6422.142\\chromedriver-win32/chromedriver.exe\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "# this may need to be updated\n",
    "# check chrome version at chrome://version\n",
    "chrome_version = \"125.0.6422.142\"\n",
    "\n",
    "chromedriver_path = ChromeDriverManager(driver_version=chrome_version).install()\n",
    "print(chromedriver_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d15f9624-4f46-4e60-96ed-47503ae5d609",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = \"https://www.gradescope.com\"\n",
    "ASSIGNMENTS_URL = \"https://www.gradescope.com/courses/489293/assignments\"\n",
    "\n",
    "EXTRACT_ASSIGNMENTS = [\"Exam 5D\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c92ecbf-1690-4b37-a7c7-7819513273f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "please log in before pressing any key to continue... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraping assignment Exam 5D: /courses/489293/assignments/2739647\n"
     ]
    }
   ],
   "source": [
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from collections import defaultdict\n",
    "import time\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "\n",
    "service = ChromeService(chromedriver_path)\n",
    "\n",
    "\n",
    "def scrape_students(driver):\n",
    "    \"\"\"get students from rubric item page\"\"\"\n",
    "    tr_elems = driver.find_elements(By.XPATH, \"//table[contains(@class, 'js-rubricItemSubmissions')]//tr\")\n",
    "    return [student_tr.text for student_tr in tr_elems]\n",
    "\n",
    "def scrape_assignment(assignment_nam, assignment_href, driver):\n",
    "    \"\"\"a helper function to generate a json with the \n",
    "    students organized by rubric items\"\"\"\n",
    "    # go to assignment statistics page if page exists\n",
    "    driver.get(f\"{BASE_URL}{assignment_href}/statistics\")\n",
    "    time.sleep(1)\n",
    "\n",
    "    # extract links to each question page\n",
    "    question_hrefs = {}\n",
    "    for question_href in driver.find_elements(By.XPATH,\n",
    "            \"//div[@class='statisticsItem--title']/a\"):\n",
    "        question_hrefs[question_href.text] = question_href.get_dom_attribute('href')\n",
    "\n",
    "    # visit each question page\n",
    "    question_rubrics = {}\n",
    "    for question_title, question_href in question_hrefs.items():\n",
    "        driver.get(f\"{BASE_URL}{question_href}\")\n",
    "        try:\n",
    "            WebDriverWait(driver, 5).until(\n",
    "                expected_conditions.presence_of_element_located((By.XPATH, \"//table[@class='table']/tbody/tr\"))\n",
    "            )\n",
    "        except TimeoutException as e:\n",
    "            print(\"timeout occured\")\n",
    "            raise e\n",
    "        \n",
    "        # get all rubric items, then for each rubric item,\n",
    "        # visit the rubric item page to extract the students to \n",
    "        # whom the item was applied\n",
    "\n",
    "        # column_title_elems = driver.find_elements(By.XPATH, \n",
    "        #     \"//td[@class='statisticsTable--column questionRubricTable--column-title']\")\n",
    "        tr_elems = driver.find_elements(By.XPATH,\n",
    "            \"//table[@class='table']/tbody/tr\")\n",
    "        \n",
    "        rubric_items = defaultdict(dict)\n",
    "        rubric_header = None\n",
    "\n",
    "        # get all the rubric items\n",
    "        for tr_elem in tr_elems:\n",
    "            column_title_elem = tr_elem.find_element(By.XPATH,\n",
    "                \"td[@class='statisticsTable--column questionRubricTable--column-title']\")\n",
    "            div_elem = column_title_elem.find_element(By.XPATH, \"./div\")\n",
    "            class_tag = div_elem.get_dom_attribute('class')\n",
    "            if not class_tag:\n",
    "                # class tag is empty, which means this is a rubric header item\n",
    "                current_header = div_elem.text\n",
    "            try:\n",
    "                link = div_elem.find_element(By.XPATH, './a')\n",
    "            except NoSuchElementException:\n",
    "                # header item has no link, so this is a rubric group name. move on to the next item.\n",
    "                continue\n",
    "\n",
    "            href = link.get_dom_attribute('href')\n",
    "            points = tr_elem.find_element(By.XPATH,\n",
    "                \"td[@class='statisticsTable--column questionRubricTable--column-points']\").text\n",
    "            if class_tag == \"table--childRow\":\n",
    "                # this rubric item belongs to a rubric group\n",
    "                rubric_items[current_header][link.text] = { 'href': href, 'points': points }\n",
    "            else:\n",
    "                # this is a regular rubric item\n",
    "                rubric_items[current_header] = { 'href': href, 'points': points }\n",
    "\n",
    "        # visit each rubric item and get students\n",
    "        for rubric_header, value in rubric_items.items():\n",
    "            if \"href\" in value:\n",
    "                # header item is a regular rubric item\n",
    "                driver.get(f\"{BASE_URL}{value['href']}\")\n",
    "                value['students'] = scrape_students(driver)\n",
    "                continue\n",
    "            for rubric_subheader, value in rubric_items[rubric_header].items():\n",
    "                driver.get(f\"{BASE_URL}{value['href']}\")\n",
    "                value['students'] = scrape_students(driver)\n",
    "\n",
    "        question_rubrics[question_title] = rubric_items\n",
    "\n",
    "    with open(f\"{assignment_name}-rubric.json\", 'w') as f:\n",
    "        json.dump(question_rubrics, f, indent=2)\n",
    "    \n",
    "\n",
    "with webdriver.Chrome(service=service, options=options) as driver:\n",
    "    driver.get(ASSIGNMENTS_URL)\n",
    "\n",
    "    input(\"please log in before pressing any key to continue...\")\n",
    "\n",
    "    assignment_elems = driver.find_elements(By.XPATH, \"//td/div[@class='assignments--rowTitle']\")\n",
    "\n",
    "    assignments = { }\n",
    "    for assignment_elem in assignment_elems:\n",
    "        href = assignment_elem.find_element(By.TAG_NAME, \"a\")\n",
    "        assignments[assignment_elem.text] = href.get_dom_attribute('href')\n",
    "    \n",
    "    for assignment_name, href in assignments.items():\n",
    "        if assignment_name in EXTRACT_ASSIGNMENTS:\n",
    "            print(f\"scraping assignment {assignment_name}: {href}\")\n",
    "            scrape_assignment(assignment_name, href, driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2e69ff-22fd-4917-98c4-27648334d8e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:selenium]",
   "language": "python",
   "name": "conda-env-selenium-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
